{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9547491,"sourceType":"datasetVersion","datasetId":5816920}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Download and Clean Dataset","metadata":{}},{"cell_type":"markdown","source":"Let's start by importing the <em>pandas</em> and the Numpy libraries.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-10-04T14:22:18.621102Z","iopub.execute_input":"2024-10-04T14:22:18.621718Z","iopub.status.idle":"2024-10-04T14:22:18.628105Z","shell.execute_reply.started":"2024-10-04T14:22:18.621666Z","shell.execute_reply":"2024-10-04T14:22:18.626674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will be using the dataset provided in the assignment\n\n<strong>The dataset is about the compressive strength of different samples of concrete based on the volumes of the different ingredients that were used to make them. Ingredients include:</strong>\n\n<strong>1. Cement</strong>\n\n<strong>2. Blast Furnace Slag</strong>\n\n<strong>3. Fly Ash</strong>\n\n<strong>4. Water</strong>\n\n<strong>5. Superplasticizer</strong>\n\n<strong>6. Coarse Aggregate</strong>\n\n<strong>7. Fine Aggregate</strong>","metadata":{}},{"cell_type":"markdown","source":"Let's read the dataset into a <em>pandas</em> dataframe.","metadata":{}},{"cell_type":"code","source":"concrete_data = pd.read_csv('/kaggle/input/concrete/concrete_data.csv')\nconcrete_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-04T14:22:18.631524Z","iopub.execute_input":"2024-10-04T14:22:18.632119Z","iopub.status.idle":"2024-10-04T14:22:18.676590Z","shell.execute_reply.started":"2024-10-04T14:22:18.632064Z","shell.execute_reply":"2024-10-04T14:22:18.675293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So the first concrete sample has 540 cubic meter of cement, 0 cubic meter of blast furnace slag, 0 cubic meter of fly ash, 162 cubic meter of water, 2.5 cubic meter of superplaticizer, 1040 cubic meter of coarse aggregate, 676 cubic meter of fine aggregate. Such a concrete mix which is 28 days old, has a compressive strength of 79.99 MPa. ","metadata":{}},{"cell_type":"markdown","source":"#### Let's check how many data points we have.","metadata":{}},{"cell_type":"code","source":"concrete_data.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-04T14:22:18.678591Z","iopub.execute_input":"2024-10-04T14:22:18.679198Z","iopub.status.idle":"2024-10-04T14:22:18.689394Z","shell.execute_reply.started":"2024-10-04T14:22:18.679138Z","shell.execute_reply":"2024-10-04T14:22:18.687802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So, there are approximately 1000 samples to train our model on. Because of the few samples, we have to be careful not to overfit the training data.","metadata":{}},{"cell_type":"markdown","source":"Let's check the dataset for any missing values.","metadata":{}},{"cell_type":"code","source":"concrete_data.describe()","metadata":{"execution":{"iopub.status.busy":"2024-10-04T14:22:18.693068Z","iopub.execute_input":"2024-10-04T14:22:18.693633Z","iopub.status.idle":"2024-10-04T14:22:18.743988Z","shell.execute_reply.started":"2024-10-04T14:22:18.693561Z","shell.execute_reply":"2024-10-04T14:22:18.742354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"concrete_data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-10-04T14:22:18.745954Z","iopub.execute_input":"2024-10-04T14:22:18.746490Z","iopub.status.idle":"2024-10-04T14:22:18.758584Z","shell.execute_reply.started":"2024-10-04T14:22:18.746440Z","shell.execute_reply":"2024-10-04T14:22:18.757095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The data looks very clean and is ready to be used to build our model.","metadata":{}},{"cell_type":"markdown","source":"#### Split data into predictors and target","metadata":{}},{"cell_type":"markdown","source":"The target variable in this problem is the concrete sample strength. Therefore, our predictors will be all the other columns.","metadata":{}},{"cell_type":"code","source":"concrete_data_columns = concrete_data.columns\npredictors = concrete_data[concrete_data_columns[concrete_data_columns != 'Strength']] # all columns except Strength\ntarget = concrete_data['Strength'] # Strength column","metadata":{"execution":{"iopub.status.busy":"2024-10-04T14:22:18.760631Z","iopub.execute_input":"2024-10-04T14:22:18.761251Z","iopub.status.idle":"2024-10-04T14:22:18.773390Z","shell.execute_reply.started":"2024-10-04T14:22:18.761185Z","shell.execute_reply":"2024-10-04T14:22:18.771825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Performing Quick Sanity Check","metadata":{}},{"cell_type":"code","source":"predictors.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-04T14:22:18.775709Z","iopub.execute_input":"2024-10-04T14:22:18.776212Z","iopub.status.idle":"2024-10-04T14:22:18.801128Z","shell.execute_reply.started":"2024-10-04T14:22:18.776166Z","shell.execute_reply":"2024-10-04T14:22:18.799376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-04T14:22:18.803147Z","iopub.execute_input":"2024-10-04T14:22:18.803783Z","iopub.status.idle":"2024-10-04T14:22:18.819093Z","shell.execute_reply.started":"2024-10-04T14:22:18.803707Z","shell.execute_reply":"2024-10-04T14:22:18.817184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finally, the last step is to normalize the data by substracting the mean and dividing by the standard deviation.","metadata":{}},{"cell_type":"code","source":"predictors_norm = (predictors - predictors.mean()) / predictors.std()\npredictors_norm.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-04T14:22:18.820976Z","iopub.execute_input":"2024-10-04T14:22:18.821516Z","iopub.status.idle":"2024-10-04T14:22:18.851081Z","shell.execute_reply.started":"2024-10-04T14:22:18.821459Z","shell.execute_reply":"2024-10-04T14:22:18.849433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_columns = predictors_norm.shape[1] # number of predictors\nn_columns","metadata":{"execution":{"iopub.status.busy":"2024-10-04T14:22:18.856884Z","iopub.execute_input":"2024-10-04T14:22:18.857425Z","iopub.status.idle":"2024-10-04T14:22:18.867491Z","shell.execute_reply.started":"2024-10-04T14:22:18.857381Z","shell.execute_reply":"2024-10-04T14:22:18.865857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"item1\"></a>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"item1\"></a>","metadata":{}},{"cell_type":"markdown","source":"## Import Keras","metadata":{}},{"cell_type":"markdown","source":"#### Let's go ahead and import the Keras library","metadata":{}},{"cell_type":"code","source":"import keras","metadata":{"execution":{"iopub.status.busy":"2024-10-04T14:22:18.869560Z","iopub.execute_input":"2024-10-04T14:22:18.870184Z","iopub.status.idle":"2024-10-04T14:22:18.879998Z","shell.execute_reply.started":"2024-10-04T14:22:18.870131Z","shell.execute_reply":"2024-10-04T14:22:18.878378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As you can see, the TensorFlow backend was used to install the Keras library.","metadata":{}},{"cell_type":"markdown","source":"Let's import the rest of the packages from the Keras library that we will need to build our regressoin model.","metadata":{}},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense","metadata":{"execution":{"iopub.status.busy":"2024-10-04T14:22:18.881851Z","iopub.execute_input":"2024-10-04T14:22:18.882402Z","iopub.status.idle":"2024-10-04T14:22:18.893448Z","shell.execute_reply.started":"2024-10-04T14:22:18.882340Z","shell.execute_reply":"2024-10-04T14:22:18.891832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define regression model\ndef regression_model():\n    # create model\n    model = Sequential()\n    model.add(Dense(10, activation='relu', input_shape=(n_columns,)))\n    model.add(Dense(10, activation='relu', input_shape=(n_columns,)))\n    model.add(Dense(10, activation='relu', input_shape=(n_columns,)))\n    model.add(Dense(1))\n    \n    # compile model\n    model.compile(optimizer='adam', loss='mean_squared_error')\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-10-04T14:22:18.895561Z","iopub.execute_input":"2024-10-04T14:22:18.896831Z","iopub.status.idle":"2024-10-04T14:22:18.908092Z","shell.execute_reply.started":"2024-10-04T14:22:18.896763Z","shell.execute_reply":"2024-10-04T14:22:18.906422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above function creates a model that has one hidden layer with 10 neurons and a ReLU activation function. It uses the adam optimizer and the mean squared error as the loss function.","metadata":{}},{"cell_type":"markdown","source":"Lets Split the data into 70/30 using Sklearn","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-10-04T14:22:18.910172Z","iopub.execute_input":"2024-10-04T14:22:18.911400Z","iopub.status.idle":"2024-10-04T14:22:18.920895Z","shell.execute_reply.started":"2024-10-04T14:22:18.911304Z","shell.execute_reply":"2024-10-04T14:22:18.919263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(predictors_norm, target, test_size=0.3, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T14:22:18.922960Z","iopub.execute_input":"2024-10-04T14:22:18.923556Z","iopub.status.idle":"2024-10-04T14:22:18.937446Z","shell.execute_reply.started":"2024-10-04T14:22:18.923506Z","shell.execute_reply":"2024-10-04T14:22:18.935811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train and Test the Network","metadata":{}},{"cell_type":"code","source":"# build the model\nmodel = regression_model()","metadata":{"execution":{"iopub.status.busy":"2024-10-04T14:22:18.940367Z","iopub.execute_input":"2024-10-04T14:22:18.940994Z","iopub.status.idle":"2024-10-04T14:22:19.020014Z","shell.execute_reply.started":"2024-10-04T14:22:18.940941Z","shell.execute_reply":"2024-10-04T14:22:19.018683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next, we will train the model for 50 epochs.\n","metadata":{}},{"cell_type":"code","source":"# fit the model\nepochs = 50\nmodel.fit(X_train, y_train, epochs=epochs, verbose=2)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T14:22:19.021958Z","iopub.execute_input":"2024-10-04T14:22:19.022419Z","iopub.status.idle":"2024-10-04T14:22:23.587426Z","shell.execute_reply.started":"2024-10-04T14:22:19.022374Z","shell.execute_reply":"2024-10-04T14:22:23.586199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next we need to evaluate the model on the test data.","metadata":{}},{"cell_type":"code","source":"loss_val = model.evaluate(X_test, y_test)\ny_pred = model.predict(X_test)\nloss_val","metadata":{"execution":{"iopub.status.busy":"2024-10-04T14:22:23.589255Z","iopub.execute_input":"2024-10-04T14:22:23.589801Z","iopub.status.idle":"2024-10-04T14:22:23.966904Z","shell.execute_reply.started":"2024-10-04T14:22:23.589745Z","shell.execute_reply":"2024-10-04T14:22:23.965567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we need to compute the mean squared error between the predicted concrete strength and the actual concrete strength.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error","metadata":{"execution":{"iopub.status.busy":"2024-10-04T14:22:23.968285Z","iopub.execute_input":"2024-10-04T14:22:23.968777Z","iopub.status.idle":"2024-10-04T14:22:23.977259Z","shell.execute_reply.started":"2024-10-04T14:22:23.968735Z","shell.execute_reply":"2024-10-04T14:22:23.976097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_square_error = mean_squared_error(y_test, y_pred)\nmean = np.mean(mean_square_error)\nstandard_deviation = np.std(mean_square_error)\nprint(mean, standard_deviation)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T14:22:23.979076Z","iopub.execute_input":"2024-10-04T14:22:23.979591Z","iopub.status.idle":"2024-10-04T14:22:23.991604Z","shell.execute_reply.started":"2024-10-04T14:22:23.979536Z","shell.execute_reply":"2024-10-04T14:22:23.990026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create a list of 50 mean squared errors and report mean and the standard deviation of the mean squared errors.","metadata":{}},{"cell_type":"code","source":"total_mean_squared_errors = 50\nepochs = 50\nmean_squared_errors = []\nfor i in range(0, total_mean_squared_errors):\n    X_train, X_test, y_train, y_test = train_test_split(predictors_norm, target, test_size=0.3, random_state=i)\n    model.fit(X_train, y_train, epochs=epochs, verbose=0)\n    MSE = model.evaluate(X_test, y_test, verbose=0)\n    print(\"MSE \"+str(i+1)+\": \"+str(MSE))\n    y_pred = model.predict(X_test)\n    mean_square_error = mean_squared_error(y_test, y_pred)\n    mean_squared_errors.append(mean_square_error)\n\nmean_squared_errors = np.array(mean_squared_errors)\nmean = np.mean(mean_squared_errors)\nstandard_deviation = np.std(mean_squared_errors)\n\nprint('\\n')\nprint(\"Below is the mean and standard deviation of \" +str(total_mean_squared_errors) + \" mean squared errors with normalized data. Total number of epochs for each training is: \" +str(epochs) + \"\\n\")\nprint(\"Mean: \"+str(mean))\nprint(\"Standard Deviation: \"+str(standard_deviation))","metadata":{"execution":{"iopub.status.busy":"2024-10-04T14:24:34.242918Z","iopub.execute_input":"2024-10-04T14:24:34.243405Z","iopub.status.idle":"2024-10-04T14:27:06.039195Z","shell.execute_reply.started":"2024-10-04T14:24:34.243353Z","shell.execute_reply":"2024-10-04T14:27:06.038008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}